{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ktPX0pCqSRN"
   },
   "source": [
    "#Продвинутый Python, ДЗ-2\n",
    "\n",
    "Правила игры:\n",
    "\n",
    "В домашке 8 задач, разбаловка указана в задании. Суммарно за дз можно получить 100 баллов, что равняется 10 баллам\n",
    "\n",
    "В каждой задаче необходимо реализовать функцию, которая после будет проверяться через github classroom на тестах. Сами тесты лежит в гитхабе, можете локально проверить работу функций перед сдачей\n",
    "\n",
    "Дедлайн - 7 дней после выдачи дз. Необходимо залить решеннный ноутбук в github и прислать ссылку в Anytask (без выполнения любого из пунктов работа проверяться не будет)\n",
    "\n",
    "В данной домашке нужно использовать pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Rlek5byfvxPo"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/60658965/7286121\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def write_and_run(line, cell):\n",
    "    argz = line.split()\n",
    "    file = argz[-1]\n",
    "    mode = 'w'\n",
    "    if len(argz) == 2 and argz[0] == '-a':\n",
    "        mode = 'a'\n",
    "    with open(file, mode, encoding='utf-8') as f:\n",
    "        f.write(cell)\n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63di75_vqbTp"
   },
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krcmq1NUqeCS"
   },
   "source": [
    "В этом домашнем задании вам придется оказаться на месте аналитика в бразильском маркетплейсе [Olist](https://olist.com/pt-br/). Вам необходимо исследовать данные и на их основании сделать выводы, которые помогут бизнесу расцветать!\n",
    "\n",
    "Данные находятся тут в файле archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5U4xc4-9b9XR"
   },
   "outputs": [],
   "source": [
    "#!pip install wget\n",
    "#перед сдачей это закомментить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ItTnixKIrtHQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 44717580 / 44717580"
     ]
    }
   ],
   "source": [
    "# Код, который будет в каждом тесте, названия не менять\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import wget\n",
    "\n",
    "url = 'https://github.com/Palladain/Deep_Python/raw/main/Homeworks/Homework_1/archive.zip'\n",
    "filename = wget.download(url)\n",
    "\n",
    "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./')\n",
    "\n",
    "customers = pd.read_csv('olist_customers_dataset.csv')\n",
    "location = pd.read_csv('olist_geolocation_dataset.csv')\n",
    "items = pd.read_csv('olist_order_items_dataset.csv')\n",
    "payments = pd.read_csv('olist_order_payments_dataset.csv')\n",
    "reviews = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "orders = pd.read_csv('olist_orders_dataset.csv')\n",
    "products = pd.read_csv('olist_products_dataset.csv')\n",
    "translation = pd.read_csv('product_category_name_translation.csv')\n",
    "sellers = pd.read_csv('olist_sellers_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLos28bYrbR2"
   },
   "source": [
    "Ван дано 9 датасетов, которые содержат в себе все данные по 100 000 заказам со всей Бразилии. Чтобы облегчить вам жизнь, вот связи по этим датасетам (файл product_category_name_translation является переводом названий категорий с португальского на английский)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXXie4hQrdhI"
   },
   "source": [
    "![](https://i.imgur.com/HRhd2Y0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pUMuhE1rWhb"
   },
   "source": [
    "Ну что же, начнем!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnjVNWlFrVKG"
   },
   "source": [
    "## Задание 1 (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Qt0BXIIvXOx"
   },
   "source": [
    "Определите:\n",
    "\n",
    "* Число товаров\n",
    "\n",
    "* Среднюю стоимость товара (стоимость товара = среднее от цен в датасете items)\n",
    "\n",
    "в разрезе категорий (все категории должны быть на английском языке)\n",
    "\n",
    "Табличка, которая у вас должна получиться:\n",
    "\n",
    "```\n",
    "category | products | price\n",
    "\n",
    "value    | value      | value\n",
    "```\n",
    "\n",
    "**Обратите внимание:**\n",
    "\n",
    "Для категории portateis_cozinha_e_preparadores_de_alimentos перевод portable kitchen and food preparers\n",
    "\n",
    "Для категории pc_gamer перевод PC Gamer\n",
    "\n",
    "Для них нужно отдельно добавить перевод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "PWVaTwBFrkFj"
   },
   "outputs": [],
   "source": [
    "%%write_and_run task_1.py\n",
    "\n",
    "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from dateutil.parser import parse\n",
    "import random\n",
    "\n",
    "category_translation = {\n",
    "    'portateis_cozinha_e_preparadores_de_alimentos': 'portable kitchen and food preparers',\n",
    "    'pc_gamer': 'PC Gamer'\n",
    "}\n",
    "\n",
    "def task_1(translation, items, products):\n",
    "    # Translate product category names.\n",
    "    translation['product_category_name'] = translation['product_category_name'].replace(category_translation)\n",
    "    \n",
    "    # Merging dataframes based on common columns.\n",
    "    merged_data = pd.merge(items, products, on='product_id')\n",
    "    merged_data = pd.merge(merged_data, translation, on='product_category_name')\n",
    "    \n",
    "    # Group by English category name and aggregate data.\n",
    "    result = merged_data.groupby('product_category_name_english').agg({'product_id': 'count', 'price': 'mean'}).reset_index()\n",
    "    result.columns = ['category', 'products', 'price']\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "VgSA5JAjxngq"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[112], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Проверки\u001b[39;00m\n\u001b[0;32m      3\u001b[0m res \u001b[38;5;241m=\u001b[39m task_1(translation, items, products)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res[res\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportable kitchen and food preparers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprice\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m186.996\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m73\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mdrop_duplicates()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m73\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "#Проверки\n",
    "\n",
    "res = task_1(translation, items, products)\n",
    "\n",
    "assert res[res.category == 'portable kitchen and food preparers'].price.values[0] == 186.996\n",
    "assert len(res) == 73\n",
    "assert len(res.drop_duplicates()) == 73\n",
    "assert res[res.category == 'drinks'].products.values[0] == 81\n",
    "assert res.products.sum() == 32341\n",
    "assert res.price.sum() == 12459.751444351941\n",
    "assert res[res.category == 'home_confort'].price.values[0] == 185.56926417326417"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUh0q89ztKMV"
   },
   "source": [
    "## Задание 2 (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PM7DzaRzO9x"
   },
   "source": [
    "Определите для каждого продавца основную категорию их продаж (категории должны быть на английском языке)\n",
    "\n",
    "Табличка, которая у вас должна получиться:\n",
    "\n",
    "```\n",
    "seller_id | category\n",
    "\n",
    "value    | value\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "YCKMxSNtzdxO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             seller_id                category\n",
      "0     0015a82c2db000af6aaaf3ae2ecb0532        small_appliances\n",
      "1     001cca7ae9ae17fb1caed9dfb1094831            garden_tools\n",
      "2     001e6ad469a905060d959994f1b41e4f          sports_leisure\n",
      "3     002100f778ceb8431b7a1020ff7ab48f         furniture_decor\n",
      "4     004c9cd9d87a3c30c522c48c4fc07416          bed_bath_table\n",
      "...                                ...                     ...\n",
      "3028  ffcfefa19b08742c5d315f2791395ee5  books_general_interest\n",
      "3029  ffdd9f82b9a447f6f8d4b91554cc7dd3              housewares\n",
      "3030  ffeee66ac5d5a62fe688b9d26f83f534         home_appliances\n",
      "3031  fffd5413c0700ac820c7069d66d98c89              housewares\n",
      "3032  ffff564a4f9085cd26170f4732393726                    auto\n",
      "\n",
      "[3033 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run task_2.py\n",
    "\n",
    "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def task_2(translation, products, items):\n",
    "    # YOUR CODE\n",
    "    products_translated = products.merge(translation, on='product_category_name', how='inner')\n",
    "    seller_categories = items.merge(products_translated, on='product_id', how='inner')\n",
    "    mode_function = lambda x: x.value_counts().index[0] if not x.empty else np.nan\n",
    "    seller_main_category = seller_categories.groupby('seller_id')['product_category_name_english'].agg(mode_function).reset_index()\n",
    "    seller_main_category.rename(columns={'product_category_name_english': 'category'}, inplace=True)\n",
    "    return seller_main_category\n",
    "result = task_2(translation, products, items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "jfx4Lfn10Tic"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res[res\u001b[38;5;241m.\u001b[39mseller_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2f73e04d12cdf0c945ded66bb3fcf6c7\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgarden_tools\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mdrop_duplicates())\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3035\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res[res\u001b[38;5;241m.\u001b[39mcategory \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtelephony\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m66\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39msort(res\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseller_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnunique\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mseller_id\u001b[38;5;241m.\u001b[39mvalues)) \u001b[38;5;241m==\u001b[39m [  \u001b[38;5;241m1\u001b[39m,   \u001b[38;5;241m1\u001b[39m,   \u001b[38;5;241m1\u001b[39m,   \u001b[38;5;241m1\u001b[39m,   \u001b[38;5;241m1\u001b[39m,   \u001b[38;5;241m2\u001b[39m,   \u001b[38;5;241m2\u001b[39m,   \u001b[38;5;241m2\u001b[39m,   \u001b[38;5;241m2\u001b[39m,   \u001b[38;5;241m2\u001b[39m,   \u001b[38;5;241m3\u001b[39m,   \u001b[38;5;241m3\u001b[39m,   \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     10\u001b[0m          \u001b[38;5;241m4\u001b[39m,   \u001b[38;5;241m4\u001b[39m,   \u001b[38;5;241m4\u001b[39m,   \u001b[38;5;241m5\u001b[39m,   \u001b[38;5;241m5\u001b[39m,   \u001b[38;5;241m5\u001b[39m,   \u001b[38;5;241m5\u001b[39m,   \u001b[38;5;241m5\u001b[39m,   \u001b[38;5;241m5\u001b[39m,   \u001b[38;5;241m6\u001b[39m,   \u001b[38;5;241m6\u001b[39m,   \u001b[38;5;241m6\u001b[39m,   \u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m     11\u001b[0m          \u001b[38;5;241m8\u001b[39m,  \u001b[38;5;241m10\u001b[39m,  \u001b[38;5;241m12\u001b[39m,  \u001b[38;5;241m13\u001b[39m,  \u001b[38;5;241m13\u001b[39m,  \u001b[38;5;241m13\u001b[39m,  \u001b[38;5;241m14\u001b[39m,  \u001b[38;5;241m14\u001b[39m,  \u001b[38;5;241m14\u001b[39m,  \u001b[38;5;241m15\u001b[39m,  \u001b[38;5;241m16\u001b[39m,  \u001b[38;5;241m17\u001b[39m,  \u001b[38;5;241m17\u001b[39m,\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;241m17\u001b[39m,  \u001b[38;5;241m19\u001b[39m,  \u001b[38;5;241m20\u001b[39m,  \u001b[38;5;241m20\u001b[39m,  \u001b[38;5;241m20\u001b[39m,  \u001b[38;5;241m21\u001b[39m,  \u001b[38;5;241m22\u001b[39m,  \u001b[38;5;241m26\u001b[39m,  \u001b[38;5;241m37\u001b[39m,  \u001b[38;5;241m37\u001b[39m,  \u001b[38;5;241m43\u001b[39m,  \u001b[38;5;241m46\u001b[39m,  \u001b[38;5;241m51\u001b[39m,\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;241m54\u001b[39m,  \u001b[38;5;241m59\u001b[39m,  \u001b[38;5;241m66\u001b[39m,  \u001b[38;5;241m66\u001b[39m,  \u001b[38;5;241m78\u001b[39m,  \u001b[38;5;241m87\u001b[39m,  \u001b[38;5;241m87\u001b[39m,  \u001b[38;5;241m99\u001b[39m, \u001b[38;5;241m101\u001b[39m, \u001b[38;5;241m116\u001b[39m, \u001b[38;5;241m125\u001b[39m, \u001b[38;5;241m156\u001b[39m, \u001b[38;5;241m216\u001b[39m,\n\u001b[0;32m     14\u001b[0m        \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m288\u001b[39m, \u001b[38;5;241m310\u001b[39m]\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Проверки\n",
    "\n",
    "res = task_2(translation, products, items)\n",
    "assert res[res.seller_id == 'e3e15e2c0b9700561efac21c6be48066'].category.values[0] == 'housewares'\n",
    "assert res[res.seller_id == '2f73e04d12cdf0c945ded66bb3fcf6c7'].category.values[0] == 'garden_tools'\n",
    "assert len(res) == len(res.drop_duplicates())\n",
    "assert len(res) == 3035\n",
    "assert len(res[res.category == 'telephony']) == 66\n",
    "assert list(np.sort(res.groupby(\"category\").agg({\"seller_id\": \"nunique\"}).seller_id.values)) == [  1,   1,   1,   1,   1,   2,   2,   2,   2,   2,   3,   3,   4,\n",
    "         4,   4,   4,   5,   5,   5,   5,   5,   5,   6,   6,   6,   7,\n",
    "         8,  10,  12,  13,  13,  13,  14,  14,  14,  15,  16,  17,  17,\n",
    "        17,  19,  20,  20,  20,  21,  22,  26,  37,  37,  43,  46,  51,\n",
    "        54,  59,  66,  66,  78,  87,  87,  99, 101, 116, 125, 156, 216,\n",
    "       224, 256, 288, 310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQemvudwt4mt"
   },
   "source": [
    "## Задание 3 (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6wytIx56ivp"
   },
   "source": [
    "Выведите долю потраченных денег по каждому штату (потраченные деньги - сумма денег по доставленным заказам, сумма по price и freight_value)\n",
    "\n",
    "*Примечание:* разбивка по штатам - по штату покупателя, процент - число от 0 до 1\n",
    "\n",
    "\n",
    "Табличка, которая у вас должна получиться:\n",
    "\n",
    "```\n",
    "state | perc\n",
    "\n",
    "value | value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WH5QCAJi3sWk"
   },
   "outputs": [],
   "source": [
    "%%write_and_run task_3.py\n",
    "\n",
    "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def task_3(orders, customers, items):\n",
    "    # YOUR CODE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gE01dmRp5YlV"
   },
   "outputs": [],
   "source": [
    "# Проверки\n",
    "\n",
    "res = task_3(orders, customers, items)\n",
    "assert res.perc.sum() == 1\n",
    "assert res[res.state == \"RS\"].perc.values[0] == 0.055868056429816286\n",
    "assert res.sort_values(\"perc\", ascending=True).iloc[0, 1] == 0.0005862290943146945\n",
    "assert res.sort_values(\"perc\", ascending=False).iloc[0, 1] == 0.3741756035817322\n",
    "assert len(res) == 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Z5KBkyet7wB"
   },
   "source": [
    "## Задание 4 (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9klcqoBj80DL"
   },
   "source": [
    "Определите средний чек покупки (добавьте разбивку на стоимость самого заказ и стоимость доставки) и среднее число товаров в заказе\n",
    "\n",
    "А также определите среднее число покупок на пользователя (обратите внимание на идентификаторы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "lMqosgB-7OeQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137.7540763788945, 22.823561713254815, 1.1417306873695092, 1.0348089410589412)\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run task_4.py\n",
    "\n",
    "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def task_4(items, orders, customers):\n",
    "    # YOUR CODE\n",
    "    orders_items = pd.merge(orders, items, on=\"order_id\")\n",
    "    avg_product_cost = orders_items.groupby('order_id')['price'].sum().mean()\n",
    "    avg_delivery_cost = orders_items.groupby('order_id')['freight_value'].sum().mean()\n",
    "\n",
    "    # Average number of items in each order\n",
    "    avg_items_per_order = orders_items.groupby('order_id')['order_item_id'].count().mean()\n",
    "\n",
    "    # Average number of purchases per unique customer\n",
    "    avg_purchases_per_customer = orders['order_id'].nunique() / customers['customer_unique_id'].nunique()\n",
    "\n",
    "    return avg_product_cost, avg_delivery_cost, avg_items_per_order, avg_purchases_per_customer\n",
    "result = task_4(items, orders, customers)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ManEB8qf7lm_"
   },
   "outputs": [],
   "source": [
    "# Проверка\n",
    "\n",
    "res = task_4(items, orders, customers)\n",
    "assert res == (137.7540763788945, 22.823561713254815, 1.1417306873695092, 1.0348089410589412)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEHsUeuYuPsK"
   },
   "source": [
    "## Задание 5 (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGX_GxAs9Fww"
   },
   "source": [
    "Посчитайте CSAT (customer satisfaction - средняя оценка ревью) и отобразите средний CSAT по дням в период с апреля 2017 по апрель 2018 года\n",
    "\n",
    "Все манипуляции с датой необходимо сделать с помощью datetime и dateutil\n",
    "\n",
    "\n",
    "Табличка, которая у вас должна получиться:\n",
    "\n",
    "```\n",
    "date | csat\n",
    "\n",
    "\"YYYY-MM-DD\" | value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Fu31Qrod9M_4"
   },
   "outputs": [],
   "source": [
    "%%write_and_run task_5.py\n",
    "\n",
    "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "\n",
    "def task_5(reviews):\n",
    "    # YOUR CODE\n",
    "    reviews['date'] = pd.to_datetime(reviews['review_creation_date'])\n",
    "\n",
    "    start_date ='2017.04.01'\n",
    "    end_date = '2018.05.01'\n",
    "    reviews_f = reviews[(reviews['date'] >=  start_date) & (reviews['date'] <  end_date)]\n",
    "    reviews_f['date'] = reviews_f['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    csat_by_day = reviews_f.groupby(['date'], as_index = False).mean()\n",
    "    csat_by_day.columns = ['date', 'csat']\n",
    "\n",
    "    return csat_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "UK4r71Vh-Pfu",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LALALALISAAA\\AppData\\Local\\Temp\\ipykernel_9968\\1983617713.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert 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 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[0;32m    498\u001b[0m     values,\n\u001b[0;32m    499\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    500\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    501\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    502\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    503\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    505\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow, values\u001b[38;5;241m.\u001b[39mdtype, is_numeric)\n\u001b[0;32m    542\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '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'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Проверки\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m task_5(reviews)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017-04-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2018-04-30\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[74], line 16\u001b[0m, in \u001b[0;36mtask_5\u001b[1;34m(reviews)\u001b[0m\n\u001b[0;32m     13\u001b[0m reviews_f \u001b[38;5;241m=\u001b[39m reviews[(reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m  start_date) \u001b[38;5;241m&\u001b[39m (reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m  end_date)]\n\u001b[0;32m     14\u001b[0m reviews_f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m reviews_f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m csat_by_day \u001b[38;5;241m=\u001b[39m reviews_f\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], as_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     17\u001b[0m csat_by_day\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m csat_by_day\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1508\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1503\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1504\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(obj, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1855\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1857\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   4666\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4667\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4668\u001b[0m     )\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum))\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1696\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert 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 to numeric"
     ]
    }
   ],
   "source": [
    "# Проверки\n",
    "res = task_5(reviews)\n",
    "assert res.date.min() == '2017-04-01'\n",
    "assert res.date.max() == '2018-04-30'\n",
    "assert res.csat.sum() == 1551.8881071384853\n",
    "assert res[res.date == '2017-07-11'].csat.values[0] == 4.291390728476821\n",
    "assert res[res.date == '2018-02-09'].csat.values[0] == 3.992156862745098\n",
    "assert res[res.csat == 3.6814814814814816].date.values[0] == '2018-02-25'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-rho7C0uUTY"
   },
   "source": [
    "## Задание 6 (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H-lma4hL-sa"
   },
   "source": [
    "Посмотрите, как быстро отвечают пользователи (сделайте аггреграцию по числу дней ответа) и какая средняя оценка\n",
    "\n",
    "Все манипуляции со временем нужно делать через datetime и dateutil\n",
    "\n",
    "Табличка, которая у вас должна получиться:\n",
    "\n",
    "```\n",
    "days | csat | orders\n",
    "\n",
    "value | value | value\n",
    "```\n",
    "\n",
    "Результаты должны быть отсориртированы по дня по возрастанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "BCjO8WQgMeGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     days      csat  orders\n",
      "0       0  3.886663   24361\n",
      "1       1  4.235586   30995\n",
      "2       2  4.048685   15898\n",
      "3       3  4.194567   14062\n",
      "4       4  4.042382    4601\n",
      "..    ...       ...     ...\n",
      "209   446  5.000000       1\n",
      "210   471  4.000000       1\n",
      "211   508  5.000000       1\n",
      "212   512  5.000000       1\n",
      "213   518  1.000000       1\n",
      "\n",
      "[214 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "%%write_and_run task_6.py\n",
    "\n",
    "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "\n",
    "def task_6(reviews):\n",
    "    # YOUR CODE\n",
    "    reviews['review_creation_date'] = pd.to_datetime(reviews['review_creation_date'])\n",
    "    reviews['review_answer_timestamp'] = pd.to_datetime(reviews['review_answer_timestamp'])\n",
    "    reviews['days'] = (reviews['review_answer_timestamp'] - reviews['review_creation_date']).dt.days\n",
    "    result = reviews.groupby('days').agg({'review_score': 'mean', 'order_id': 'count'}).reset_index()\n",
    "    result.rename(columns={'review_score': 'csat', 'order_id': 'orders'}, inplace=True)\n",
    "    result = result.sort_values(by='days')\n",
    "\n",
    "    return result\n",
    "reviews = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "res = task_6(reviews)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "b_zq1nfxOvZa"
   },
   "outputs": [],
   "source": [
    "# Проверки\n",
    "res = task_6(reviews)\n",
    "assert res.orders.sum() == 99224\n",
    "assert np.all(res.days.values == np.sort(res.days.values))\n",
    "assert len(res) == 214\n",
    "assert res.days.min() == 0\n",
    "assert res.days.max() == 518\n",
    "assert res[res.days == 233].csat.values[0] == 3.0\n",
    "assert res[res.days == 87].orders.values[0] == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc-MZgP2udIi"
   },
   "source": [
    "## Задание 7 (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxkpI1l0QO0i"
   },
   "source": [
    "Выделите все заказы, где не проставлено поле order_delivered_customer_date. Замените его на дату '2999-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "oqIpnXvbP3FZ"
   },
   "outputs": [],
   "source": [
    "%%write_and_run task_7.py\n",
    "\n",
    "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def task_7(orders):\n",
    "    # YOUR CODE\n",
    "    orders['order_delivered_customer_date'].fillna('2999-12-31', inplace=True)\n",
    "    return orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "k6z59EMXWLkm"
   },
   "outputs": [],
   "source": [
    "#Проверки\n",
    "\n",
    "res = task_7(orders)\n",
    "assert len(res[res.order_delivered_customer_date.isna()]) == 0\n",
    "assert len(res) == 99441\n",
    "assert len(res[res.order_delivered_customer_date == '2999-12-31']) == 2965"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVbTTB9nuiHH"
   },
   "source": [
    "## Задание 8 (30 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeRxv6FDVeVJ"
   },
   "source": [
    "Определите топ-10 продавцов, у которых больше 100 заказов, отсылающие чаще всего свою посылку в другие регионы (считаются только доставленные заказы)\n",
    "\n",
    "Чаще всего отсылают = самый большой процент отправленных заказов в другой штат\n",
    "\n",
    "Табличка, которая у вас должна получиться:\n",
    "\n",
    "```\n",
    "seller_id | share\n",
    "\n",
    "value | value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nv1eFCg5WnlD"
   },
   "outputs": [],
   "source": [
    "%%write_and_run task_8.py\n",
    "\n",
    "# важно! все зависимости, которые используете (если добавляее новые) в этом классе надо явно продублировать в эту ячейку\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def task_8(orders, items, sellers, customers):\n",
    "    # YOUR CODE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bC_uAYIbRrn"
   },
   "outputs": [],
   "source": [
    "# Проверки\n",
    "\n",
    "res = task_8(orders, items, sellers, customers)\n",
    "assert np.all(res.share.values == np.sort(res.share.values)[::-1])\n",
    "assert res.share.values[0] == 0.9743589743589743\n",
    "assert res.share.values[-1] == 0.9356435643564357\n",
    "assert res.seller_id.values[5] == '1b4c3a6f53068f0b6944d2d005c9fc89'\n",
    "assert res.seller_id.values[2] == '06a2c3af7b3aee5d69171b0e14f0ee87'\n",
    "assert res.share.sum() == 9.519118744616716"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
